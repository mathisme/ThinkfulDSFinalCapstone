{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0485b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c1391a",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8448b0b9",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "move this later\n",
    "\n",
    "1.  https://www.webmd.com/heart-disease/default.htm\n",
    "2.  https://www.webmd.com/cholesterol-management/default.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c74e4c",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Heart disease is \"is the leading cause of death for men and women in the U.S.\"1  And, having high cholesterol is a major risk factor for heart disease.2  The goal of my project is to try to use NHANES survey data to predict total cholesterol level.  A model that predicts total cholesterol level from health information would be benificial to health apps.  If a fittness/health app can predict total cholesterol level, they can notify the user if their cholesterol level is high, promoting they see a doctor and hence reduce heart disease risk.\n",
    "\n",
    "## note to self, may want to expand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a56ae",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The National Health and Nutrition Examination Survey is a yearly health exam and survey conducted by the CDC to gauge the overall health status of US citizens.  Each survey consists of multiple datasets in SAS format.\n",
    "\n",
    "The datasets and variables I intend to use for modeling are...\n",
    "\n",
    "The reasons for chosing these variables are...\n",
    "\n",
    "## notes\n",
    "later want to say you only used first day nutrition\n",
    "may want to change variables to only include recreation info and say why you only used recreational activity info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f383d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anned\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\sas\\sas_xport.py:475: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x] = v\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LBXTC</th>\n",
       "      <th>PHAFSTHR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDRETH3</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>BMXWT</th>\n",
       "      <th>BMXHT</th>\n",
       "      <th>BMXBMI</th>\n",
       "      <th>BPXSY1</th>\n",
       "      <th>BPXSY2</th>\n",
       "      <th>...</th>\n",
       "      <th>PAQ620</th>\n",
       "      <th>PAQ625</th>\n",
       "      <th>PAD630</th>\n",
       "      <th>PAQ650</th>\n",
       "      <th>PAQ655</th>\n",
       "      <th>PAD660</th>\n",
       "      <th>PAQ665</th>\n",
       "      <th>PAQ670</th>\n",
       "      <th>PAD675</th>\n",
       "      <th>KIQ022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>94.8</td>\n",
       "      <td>184.5</td>\n",
       "      <td>27.8</td>\n",
       "      <td>128.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>265.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>90.4</td>\n",
       "      <td>171.4</td>\n",
       "      <td>30.8</td>\n",
       "      <td>146.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>229.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>83.4</td>\n",
       "      <td>170.1</td>\n",
       "      <td>28.8</td>\n",
       "      <td>138.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>109.8</td>\n",
       "      <td>160.9</td>\n",
       "      <td>42.4</td>\n",
       "      <td>132.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>55.2</td>\n",
       "      <td>164.9</td>\n",
       "      <td>20.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LBXTC  PHAFSTHR  RIAGENDR  RIDRETH3  RIDAGEYR  BMXWT  BMXHT  BMXBMI  \\\n",
       "0  173.0       3.0       1.0       3.0      62.0   94.8  184.5    27.8   \n",
       "1  265.0      12.0       1.0       3.0      53.0   90.4  171.4    30.8   \n",
       "2  229.0      10.0       1.0       3.0      78.0   83.4  170.1    28.8   \n",
       "3  174.0       2.0       2.0       3.0      56.0  109.8  160.9    42.4   \n",
       "4  204.0      10.0       2.0       4.0      42.0   55.2  164.9    20.3   \n",
       "\n",
       "   BPXSY1  BPXSY2  ...  PAQ620  PAQ625  PAD630  PAQ650  PAQ655  PAD660  \\\n",
       "0   128.0   124.0  ...     1.0     5.0    10.0     2.0     NaN     NaN   \n",
       "1   146.0   140.0  ...     2.0     NaN     NaN     2.0     NaN     NaN   \n",
       "2   138.0   132.0  ...     1.0     4.0   240.0     2.0     NaN     NaN   \n",
       "3   132.0   134.0  ...     1.0     5.0    90.0     2.0     NaN     NaN   \n",
       "4   100.0   114.0  ...     1.0     7.0   480.0     2.0     NaN     NaN   \n",
       "\n",
       "   PAQ665  PAQ670  PAD675  KIQ022  \n",
       "0     1.0     6.0    30.0     NaN  \n",
       "1     2.0     NaN     NaN     NaN  \n",
       "2     2.0     NaN     NaN     NaN  \n",
       "3     2.0     NaN     NaN     NaN  \n",
       "4     2.0     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in the data\n",
    "file_list = pd.read_csv('files.csv')\n",
    "variables = pd.read_csv('variables.csv')\n",
    "years = file_list.Year.unique()\n",
    "dfs = [None]*2\n",
    "for i in range(len(years)):\n",
    "    files = file_list[file_list.Year == years[i]]\n",
    "    first = files[files.Notes==\"read in first\"]\n",
    "    first_path = list(first[\"Path\"])[0]\n",
    "    first_type = list(first[\"Dataset_Description\"])[0]\n",
    "    first_variables = list(variables[variables.Dataset_Description==first_type][\"Variable_Name\"])\n",
    "    df = pd.read_sas(first_path)\n",
    "    df = df[first_variables].copy()\n",
    "    others = files[files.Notes!=\"read in first\"]\n",
    "    for other_path in others[\"Path\"]:\n",
    "        other_type = list(others[others[\"Path\"]==other_path][\"Dataset_Description\"])[0]\n",
    "        temp_df = pd.read_sas(other_path)\n",
    "        other_variables = [\"SEQN\"] + list(variables[variables.Dataset_Description==other_type][\"Variable_Name\"])\n",
    "        temp_df = temp_df[other_variables].copy()\n",
    "        df = df.merge(temp_df, on=\"SEQN\", how=\"left\")\n",
    "    df.drop(\"SEQN\", axis=1, inplace=True)\n",
    "    dfs[i] = df.copy()\n",
    "df = pd.concat(dfs,ignore_index=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1d2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
